import os
import sys
import threading
import webbrowser
import gradio as gr
from langchain_community.llms import Ollama
from langchain_core.prompts import PromptTemplate
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import Chroma
from langchain_ollama import OllamaEmbeddings
from langchain_community.cache import InMemoryCache
import langchain

# ====== C·∫•u h√¨nh cache ======
langchain.llm_cache = InMemoryCache()

# ====== C·∫•u h√¨nh chatbot ======
DATA_PATH = os.path.join("kien_thuc_giao_duc.txt")
CHROMA_DIR = "data/chroma_db"
OLLAMA_BASE = "http://127.0.0.1:11434"

EMBED_MODEL = "nomic-embed-text"
LLM_MODEL = "llama3.1:8b"

# ====== 1) Load d·ªØ li·ªáu ======
if not os.path.exists(DATA_PATH):
    raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu: {DATA_PATH}")

loader = TextLoader(DATA_PATH, encoding="utf-8")
documents = loader.load()

# ====== 2) Chia nh·ªè vƒÉn b·∫£n ======
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = splitter.split_documents(documents)

# ====== 3) Embedding + Chroma vectorstore ======
embeddings = OllamaEmbeddings(model=EMBED_MODEL, base_url=OLLAMA_BASE)

if not os.path.exists(CHROMA_DIR):
    vectorstore = Chroma.from_documents(
        chunks, embedding=embeddings, persist_directory=CHROMA_DIR
    )
    vectorstore.persist()
else:
    vectorstore = Chroma(
        persist_directory=CHROMA_DIR,
        embedding_function=embeddings
    )

# ====== 4) LLM ======
llm = Ollama(model=LLM_MODEL, base_url=OLLAMA_BASE)

# ====== 5) Prompt ======
EDU_PROMPT = """
B·∫°n l√† tr·ª£ l√Ω h·ªçc v·ª• c·ªßa Tr∆∞·ªùng ƒê·∫°i h·ªçc C·∫ßn Th∆° (CTU), nhi·ªám v·ª•:

- Tr·∫£ l·ªùi CH√çNH X√ÅC v√† NG·∫ÆN G·ªåN d·ª±a tr√™n d·ªØ li·ªáu trong [CONTEXT].
- KH√îNG ƒë∆∞·ª£c b·ªãa th√¥ng tin.
- N·∫øu c√¢u h·ªèi ngo√†i ph·∫°m vi h·ªçc v·ª•, sinh vi√™n, CTU ‚Üí tr·∫£ l·ªùi:
  "Xin l·ªói, t√¥i ch·ªâ h·ªó tr·ª£ th√¥ng tin li√™n quan ƒë·∫øn h·ªçc v·ª• v√† sinh vi√™n Tr∆∞·ªùng ƒê·∫°i h·ªçc C·∫ßn Th∆°."
- N·∫øu kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p trong context ‚Üí tr·∫£ l·ªùi:
  "T√¥i ch∆∞a c√≥ d·ªØ li·ªáu v·ªÅ n·ªôi dung n√†y."

D∆∞·ªõi ƒë√¢y l√† d·ªØ li·ªáu b·∫°n ƒë∆∞·ª£c ph√©p s·ª≠ d·ª•ng:

[CONTEXT]
{context}

C√¢u h·ªèi: {question}

Tr·∫£ l·ªùi:
"""

prompt = PromptTemplate(
    input_variables=["context", "question"],
    template=EDU_PROMPT
)

# ====== 6) H√†m tr·∫£ l·ªùi ======
def chatbot_ctu(user_input, chat_history):
    # T√¨m ƒëo·∫°n vƒÉn ph√π h·ª£p
    results = vectorstore.similarity_search(user_input, k=4)
    context = "\n\n".join([doc.page_content for doc in results]) if results else ""

    # Kh√¥ng c√≥ d·ªØ li·ªáu RAG
    if not context:
        answer = "T√¥i ch∆∞a c√≥ d·ªØ li·ªáu v·ªÅ n·ªôi dung n√†y."
    else:
        final_prompt = prompt.format(context=context, question=user_input)
        answer = llm.invoke(final_prompt)   # Gemma kh√¥ng d√πng stream t·ªët

    chat_history.append((user_input, answer))
    return chat_history, chat_history

# ====== 7) Giao di·ªán Gradio ======
with gr.Blocks(title="üéì Chatbot Sinh vi√™n CTU") as demo:
    gr.Markdown("## üéì Chatbot Sinh vi√™n CTU\nH·ªó tr·ª£ h·ªçc v·ª•, ƒëƒÉng k√Ω h·ªçc ph·∫ßn, h·ªçc ph√≠, quy ƒë·ªãnh, tuy·ªÉn sinh...")

    chat_history = gr.Chatbot(label="Tr·ª£ l√Ω CTU")
    user_input = gr.Textbox(placeholder="Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n...", label="B·∫°n:")
    submit_btn = gr.Button("G·ª≠i")

    submit_btn.click(
        fn=chatbot_ctu,
        inputs=[user_input, chat_history],
        outputs=[chat_history, chat_history]
    )
# ====== 8) T·ª± ƒë·ªông m·ªü trang web khi ch·∫°y ======
webbrowser.open("http://127.0.0.1:7860")
# ====== 9) Nh·∫•n 'q' trong TERMINAL ƒë·ªÉ tho√°t ======
def listen_for_exit():
    print("Nh·∫•n 'q' trong terminal ƒë·ªÉ d·ª´ng ch∆∞∆°ng tr√¨nh.")
    while True:
        key = sys.stdin.readline().strip().lower()
        if key == "q":
            print("ƒê√£ nh·∫≠n l·ªánh tho√°t. R·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n!")
            os._exit(0)

listener_thread = threading.Thread(target=listen_for_exit, daemon=True)
listener_thread.start()
demo.launch()